---
layout:     post                    # ä½¿ç”¨çš„å¸ƒå±€ï¼ˆä¸éœ€è¦æ”¹ï¼‰
title:      ç¥ç»ç½‘ç»œä¼˜åŒ–              # æ ‡é¢˜ 
subtitle: Â  äººå·¥æ™ºèƒ½å®è·µï¼šTensorflowç¬”è®°ï¼ˆ6ï¼‰ #å‰¯æ ‡é¢˜
date: Â  Â  Â  2018-04-04 Â  Â  Â  Â  Â  Â   # æ—¶é—´
author: Â  Â  KeyonÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # ä½œè€…
header-img: img/post-bg-tf6.jpg    #è¿™ç¯‡æ–‡ç« æ ‡é¢˜èƒŒæ™¯å›¾ç‰‡
catalog: true                       # æ˜¯å¦å½’æ¡£
tags:
 æœºå™¨å­¦ä¹ 
---

## æŸå¤±å‡½æ•°
**ç¥ç»å…ƒæ¨¡å‹**ï¼šç”¨æ•°å­¦å…¬å¼è¡¨ç¤ºä¸ºï¼šğŸ(âˆ‘ğ’Šğ’™ğ’Šğ’˜ğ’Š + ğ›)ï¼Œf ä¸ºæ¿€æ´»å‡½æ•°ã€‚ç¥ç»ç½‘ç»œæ˜¯ä»¥ç¥ç»å…ƒä¸ºåŸºæœ¬å•å…ƒæ„æˆçš„ã€‚

**æ¿€æ´»å‡½æ•°**ï¼šå¼•å…¥éçº¿æ€§æ¿€æ´»å› ç´ ï¼Œæé«˜æ¨¡å‹çš„è¡¨è¾¾åŠ›ã€‚

å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°æœ‰ reluã€sigmoidã€tanh ç­‰ï¼š

æ¿€æ´»å‡½æ•° reluï¼š åœ¨ Tensorflow ä¸­ï¼Œç”¨ tf.nn.relu()è¡¨ç¤º

![](https://ws1.sinaimg.cn/large/006tKfTcgy1fpzmd9aykij31180bawha.jpg)

æ¿€æ´»å‡½æ•° sigmoidï¼šåœ¨ Tensorflow ä¸­ï¼Œç”¨ tf.nn.sigmoid()è¡¨ç¤º

![](https://ws1.sinaimg.cn/large/006tKfTcgy1fpzmdi0jkpj30zy0b0wgq.jpg)

æ¿€æ´»å‡½æ•° tanhï¼šåœ¨ Tensorflow ä¸­ï¼Œç”¨ tf.nn.tanh()è¡¨ç¤º

![](https://ws1.sinaimg.cn/large/006tKfTcgy1fpzmdna17mj30zk0ca0v1.jpg)

**ç¥ç»ç½‘ç»œçš„å¤æ‚åº¦**ï¼šå¯ç”¨ç¥ç»ç½‘ç»œçš„å±‚æ•°å’Œç¥ç»ç½‘ç»œä¸­å¾…ä¼˜åŒ–å‚æ•°ä¸ªæ•°è¡¨ç¤ºã€‚

**ç¥ç»ç½‘è·¯çš„å±‚æ•°**ï¼šä¸€èˆ¬ä¸è®¡å…¥è¾“å…¥å±‚ï¼Œå±‚æ•° = n ä¸ªéšè—å±‚ + 1 ä¸ªè¾“å‡ºå±‚ã€‚

**ç¥ç»ç½‘è·¯å¾…ä¼˜åŒ–çš„å‚æ•°**ï¼šç¥ç»ç½‘ç»œä¸­æ‰€æœ‰å‚æ•° w çš„ä¸ªæ•° + æ‰€æœ‰å‚æ•° b çš„ä¸ªæ•°ã€‚

**æŸå¤±å‡½æ•°(loss)**ï¼šç”¨æ¥è¡¨ç¤ºé¢„æµ‹å€¼(y)ä¸å·²çŸ¥ç­”æ¡ˆ(y_)çš„å·®è·ã€‚

å¸¸ç”¨çš„æŸå¤±å‡½æ•°æœ‰**å‡æ–¹è¯¯å·®**ã€**è‡ªå®šä¹‰**å’Œ**äº¤å‰ç†µ**ç­‰ã€‚

**å‡æ–¹è¯¯å·® mse**ï¼šn ä¸ªæ ·æœ¬çš„é¢„æµ‹å€¼ y ä¸å·²çŸ¥ç­”æ¡ˆ y_ ä¹‹å·®çš„å¹³æ–¹å’Œï¼Œå†æ±‚å¹³å‡å€¼ã€‚

![](https://ws4.sinaimg.cn/large/006tKfTcgy1fpzmcfpt1cj30gw03s74k.jpg)

> åœ¨ Tensorflow ä¸­ç”¨ loss_mse = tf.reduce_mean(tf.square(y_ - y))

**è‡ªå®šä¹‰æŸå¤±å‡½æ•°**ï¼šæ ¹æ®é—®é¢˜çš„å®é™…æƒ…å†µï¼Œå®šåˆ¶åˆç†çš„æŸå¤±å‡½æ•°ã€‚

è‡ªå®šä¹‰æŸå¤±å‡½æ•°ä¸ºï¼šloss = âˆ‘ğ‘›ğ‘“(y_, y)

> ç”¨ Tensorflow å‡½æ•°è¡¨ç¤ºä¸ºï¼šloss = tf.reduce_sum(tf.where(tf.greater(y,y_),COST(y-y_),PROFIT(y_-y)))

**äº¤å‰ç†µ(Cross Entropy)**ï¼šè¡¨ç¤ºä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„è·ç¦»ã€‚äº¤å‰ç†µè¶Šå¤§ï¼Œä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒè·ç¦»è¶Šè¿œï¼Œä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒè¶Šç›¸å¼‚ï¼›äº¤å‰ç†µè¶Šå°ï¼Œä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒè·ç¦»è¶Šè¿‘ï¼Œä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒè¶Šç›¸ä¼¼ã€‚

äº¤å‰ç†µè®¡ç®—å…¬å¼ï¼šğ‡(ğ²_ , ğ²) = âˆ’âˆ‘ğ²_ âˆ— ğ’ğ’ğ’ˆ ğ’š

> ç”¨ Tensorflow å‡½æ•°è¡¨ç¤ºä¸º
> ce= -tf.reduce_mean(y_* tf.log(tf.clip_by_value(y, 1e-12, 1.0)))

**softmax å‡½æ•°**ï¼šå°† n åˆ†ç±»çš„ n ä¸ªè¾“å‡º(y1,y2...yn)å˜ä¸ºæ»¡è¶³ä»¥ä¸‹æ¦‚ç‡åˆ†å¸ƒè¦æ±‚çš„å‡½æ•°ã€‚

![](https://ws2.sinaimg.cn/large/006tKfTcgy1fpzmc6le3tj311c04et9a.jpg)

softmax å‡½æ•°è¡¨ç¤ºä¸ºï¼š

![](https://ws1.sinaimg.cn/large/006tKfTcgy1fpzmbx4sllj30gs05cmxk.jpg)

softmax å‡½æ•°åº”ç”¨ï¼šåœ¨ n åˆ†ç±»ä¸­ï¼Œæ¨¡å‹ä¼šæœ‰ n ä¸ªè¾“å‡ºï¼Œå³ y1,y2...ynï¼Œå…¶ä¸­ yi è¡¨ç¤ºç¬¬ i ç§æƒ…å†µå‡ºç°çš„å¯ èƒ½æ€§å¤§å°ã€‚å°† n ä¸ªè¾“å‡ºç»è¿‡ softmax å‡½æ•°ï¼Œå¯å¾—åˆ°ç¬¦åˆæ¦‚ç‡åˆ†å¸ƒçš„åˆ†ç±»ç»“æœã€‚

åœ¨ Tensorflow ä¸­ï¼Œä¸€èˆ¬è®©æ¨¡å‹çš„è¾“å‡ºç»è¿‡ sofemax å‡½æ•°ï¼Œä»¥è·å¾—è¾“å‡ºåˆ†ç±»çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå†ä¸æ ‡å‡†ç­”æ¡ˆå¯¹æ¯”ï¼Œæ±‚å‡ºäº¤å‰ç†µï¼Œå¾—åˆ°æŸå¤±å‡½æ•°ï¼Œç”¨å¦‚ä¸‹å‡½æ•°å®ç°ï¼š

```
ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1)) 
cem = tf.reduce_mean(ce)
```

## å­¦ä¹ ç‡
å­¦ä¹ ç‡ learning_rateï¼šè¡¨ç¤ºäº†æ¯æ¬¡å‚æ•°æ›´æ–°çš„å¹…åº¦å¤§å°ã€‚å­¦ä¹ ç‡è¿‡å¤§ï¼Œä¼šå¯¼è‡´å¾…ä¼˜åŒ–çš„å‚æ•°åœ¨æœ€å°å€¼é™„è¿‘æ³¢åŠ¨ï¼Œä¸æ”¶æ•›;å­¦ä¹ ç‡è¿‡å°ï¼Œä¼šå¯¼è‡´å¾…ä¼˜åŒ–çš„å‚æ•°æ”¶æ•›ç¼“æ…¢ã€‚ 

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå‚æ•°çš„æ›´æ–°å‘ç€æŸå¤±å‡½æ•°æ¢¯åº¦ä¸‹é™çš„æ–¹å‘ã€‚

å‚æ•°çš„æ›´æ–°å…¬å¼ä¸ºï¼š

![](https://ws4.sinaimg.cn/large/006tKfTcgy1fpzmmhw5u5j30qk03u0t1.jpg)

**å­¦ä¹ ç‡çš„è®¾ç½®**ï¼šå­¦ä¹ ç‡è¿‡å¤§ï¼Œä¼šå¯¼è‡´å¾…ä¼˜åŒ–çš„å‚æ•°åœ¨æœ€å°å€¼é™„è¿‘æ³¢åŠ¨ï¼Œä¸æ”¶æ•›ï¼›å­¦ä¹ ç‡è¿‡å°ï¼Œä¼šå¯¼è‡´å¾…ä¼˜åŒ–çš„å‚æ•°æ”¶æ•›ç¼“æ…¢ã€‚

**æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡**ï¼šå­¦ä¹ ç‡éšç€è®­ç»ƒè½®æ•°å˜åŒ–è€ŒåŠ¨æ€æ›´æ–°ã€‚

å­¦ä¹ ç‡è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š

![](https://ws1.sinaimg.cn/large/006tKfTcgy1fpzmmnzy92j31j603odgs.jpg)

ç”¨ Tensorflow çš„å‡½æ•°è¡¨ç¤ºä¸ºï¼š

```
global_step = tf.Variable(0, trainable=False)
learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE,global_step,LEARNING_RATE_STEP, LEARNING_RATE_DECAY,staircase=True/False)
```

å…¶ä¸­ï¼ŒLEARNING_RATE_BASE ä¸ºå­¦ä¹ ç‡åˆå§‹å€¼ï¼ŒLEARNING_RATE_DECAY ä¸ºå­¦ä¹ ç‡è¡°å‡ç‡ï¼Œglobal_step è®° å½•äº†å½“å‰è®­ç»ƒè½®æ•°ï¼Œä¸ºä¸å¯è®­ç»ƒå‹å‚æ•°ã€‚å­¦ä¹ ç‡ learning_rate æ›´æ–°é¢‘ç‡ä¸ºè¾“å…¥æ•°æ®é›†æ€»æ ·æœ¬æ•°é™¤ä»¥æ¯æ¬¡å–‚å…¥æ ·æœ¬æ•°ã€‚è‹¥ staircase è®¾ç½®ä¸º True æ—¶ï¼Œè¡¨ç¤º global_step/learning rate step å–æ•´æ•°ï¼Œå­¦ä¹ ç‡é˜¶æ¢¯å‹è¡°å‡ï¼›è‹¥ staircase è®¾ç½®ä¸º false æ—¶ï¼Œå­¦ä¹ ç‡ä¼šæ˜¯ä¸€æ¡å¹³æ»‘ä¸‹é™çš„æ›²çº¿ã€‚

## æ»‘åŠ¨å¹³å‡
**æ»‘åŠ¨å¹³å‡**ï¼šè®°å½•äº†ä¸€æ®µæ—¶é—´å†…æ¨¡å‹ä¸­æ‰€æœ‰å‚æ•° w å’Œ b å„è‡ªçš„å¹³å‡å€¼ã€‚åˆ©ç”¨æ»‘åŠ¨å¹³å‡å€¼å¯ä»¥å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æ»‘åŠ¨å¹³å‡å€¼(å½±å­)è®¡ç®—å…¬å¼**ï¼šå½±å­ = è¡°å‡ç‡ * å½±å­ +(1 - è¡°å‡ç‡)* å‚æ•°

![](https://ws2.sinaimg.cn/large/006tKfTcgy1fpzmsn6jptj311e034ab8.jpg)

ç”¨ Tesnsorflow å‡½æ•°è¡¨ç¤ºä¸ºï¼š

```
ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAYï¼Œglobal_step) 
#å…¶ä¸­ï¼ŒMOVING_AVERAGE_DECAY è¡¨ç¤ºæ»‘åŠ¨å¹³å‡è¡°å‡ç‡ï¼Œä¸€èˆ¬ä¼šèµ‹æ¥è¿‘ 1 çš„å€¼ï¼Œglobal_step è¡¨ç¤ºå½“å‰è®­ç»ƒäº†å¤šå°‘è½®ã€‚
ema_op = ema.apply(tf.trainable_variables()) 
#å…¶ä¸­ï¼Œema.apply()å‡½æ•°å®ç°å¯¹æ‹¬å·å†…å‚æ•°æ±‚æ»‘åŠ¨å¹³å‡ï¼Œtf.trainable_variables()å‡½æ•°å®ç°æŠŠæ‰€æœ‰å¾…è®­ç»ƒå‚æ•°æ±‡æ€»ä¸ºåˆ—è¡¨ã€‚
with tf.control_dependencies([train_step, ema_op]):
	train_op = tf.no_op(name='train')
#å…¶ä¸­ï¼Œè¯¥å‡½æ•°å®ç°å°†æ»‘åŠ¨å¹³å‡å’Œè®­ç»ƒè¿‡ç¨‹åŒæ­¥è¿è¡Œã€‚
#æŸ¥çœ‹æ¨¡å‹ä¸­å‚æ•°çš„å¹³å‡å€¼ï¼Œå¯ä»¥ç”¨ ema.average()å‡½æ•°ã€‚
```

## æ­£åˆ™åŒ–
**è¿‡æ‹Ÿåˆ**ï¼šç¥ç»ç½‘ç»œæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡è¾ƒé«˜ï¼Œåœ¨æ–°çš„æ•°æ®è¿›è¡Œé¢„æµ‹æˆ–åˆ†ç±»æ—¶å‡†ç¡®ç‡è¾ƒä½ï¼Œè¯´æ˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å·®ã€‚

**æ­£åˆ™åŒ–**ï¼šåœ¨æŸå¤±å‡½æ•°ä¸­ç»™æ¯ä¸ªå‚æ•° w åŠ ä¸Šæƒé‡ï¼Œå¼•å…¥æ¨¡å‹å¤æ‚åº¦æŒ‡æ ‡ï¼Œä»è€ŒæŠ‘åˆ¶æ¨¡å‹å™ªå£°ï¼Œå‡å°è¿‡æ‹Ÿåˆã€‚

ä½¿ç”¨æ­£åˆ™åŒ–åï¼ŒæŸå¤±å‡½æ•° loss å˜ä¸ºä¸¤é¡¹ä¹‹å’Œï¼š

![](https://ws4.sinaimg.cn/large/006tKfTcgy1fpzniuhfpbj30ve032dg6.jpg)

å…¶ä¸­ï¼Œç¬¬ä¸€é¡¹æ˜¯é¢„æµ‹ç»“æœä¸æ ‡å‡†ç­”æ¡ˆä¹‹é—´çš„å·®è·ï¼Œå¦‚ä¹‹å‰è®²è¿‡çš„äº¤å‰ç†µã€å‡æ–¹è¯¯å·®ç­‰ï¼›ç¬¬äºŒé¡¹æ˜¯æ­£åˆ™åŒ–è®¡ç®—ç»“æœã€‚

æ­£åˆ™åŒ–è®¡ç®—æ–¹æ³•ï¼š

L1 æ­£åˆ™åŒ–ï¼š ğ’ğ’ğ’”ğ’”ğ‘³ğŸ = âˆ‘ğ’Š ğ’˜ğ’Š

> ç”¨ Tesnsorflow å‡½æ•°è¡¨ç¤ºï¼šloss(w) = tf.contrib.layers.l1_regularizer(REGULARIZER)(w)

L2 æ­£åˆ™åŒ–ï¼š ğ’ğ’ğ’”ğ’”ğ‘³ğŸ = âˆ‘ğ’Š ğ’˜ğ’Š ğŸ

> ç”¨ Tesnsorflow å‡½æ•°è¡¨ç¤ºï¼šloss(w) = tf.contrib.layers.l2_regularizer(REGULARIZER)(w)

ç”¨ Tesnsorflow å‡½æ•°å®ç°æ­£åˆ™åŒ–ï¼š

```
tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(regularizer)(w) 
loss = cem + tf.add_n(tf.get_collection('losses'))
```

**matplotlib æ¨¡å—**ï¼šPython ä¸­çš„å¯è§†åŒ–å·¥å…·æ¨¡å—ï¼Œå®ç°å‡½æ•°å¯è§†åŒ–ã€‚

> ç»ˆç«¯å®‰è£…æŒ‡ä»¤ï¼šsudo pip install matplotlib

å‡½æ•° plt.scatter()ï¼šåˆ©ç”¨æŒ‡å®šé¢œè‰²å®ç°ç‚¹(x,y)çš„å¯è§†åŒ–ã€‚

```
plt.scatter (x åæ ‡, y åæ ‡, c=â€é¢œè‰²â€)
plt.show()
```

æ”¶é›†è§„å®šåŒºåŸŸå†…æ‰€æœ‰çš„ç½‘æ ¼åæ ‡ç‚¹ï¼š

```
xx, yy = np.mgrid[èµ·:æ­¢:æ­¥é•¿, èµ·:æ­¢:æ­¥é•¿] #æ‰¾åˆ°è§„å®šåŒºåŸŸä»¥æ­¥é•¿ä¸ºåˆ†è¾¨ç‡çš„è¡Œåˆ—ç½‘æ ¼åæ ‡ç‚¹ 
grid = np.c_[xx.ravel(), yy.ravel()] #æ”¶é›†è§„å®šåŒºåŸŸå†…æ‰€æœ‰çš„ç½‘æ ¼åæ ‡ç‚¹
```

å‡½æ•° plt.contour()ï¼šå‘ŠçŸ¥ xã€y åæ ‡å’Œå„ç‚¹é«˜åº¦ï¼Œç”¨ levels æŒ‡å®šé«˜åº¦çš„ç‚¹æä¸Šé¢œè‰²ã€‚

```
plt.contour (x è½´åæ ‡å€¼, y è½´åæ ‡å€¼, è¯¥ç‚¹çš„é«˜åº¦, levels=[ç­‰é«˜çº¿çš„é«˜åº¦])
plt.show()
```

## ç¥ç»ç½‘ç»œæ­å»ºå…«è‚¡
**å‰å‘ä¼ æ’­ï¼šç”±è¾“å…¥åˆ°è¾“å‡ºï¼Œæ­å»ºå®Œæ•´çš„ç½‘ç»œç»“æ„ã€‚**

```
def forward(x, regularizer):
	w=
	b=
	y= 
	return y

```

ç¬¬ä¸€ä¸ªå‡½æ•° forward()å®Œæˆç½‘ç»œç»“æ„çš„è®¾è®¡ï¼Œä»è¾“å…¥åˆ°è¾“å‡ºæ­å»ºå®Œæ•´çš„ç½‘ç»œç»“æ„ï¼Œå®ç°å‰å‘ä¼ æ’­è¿‡ç¨‹ã€‚ è¯¥å‡½æ•°ä¸­ï¼Œå‚æ•° x ä¸ºè¾“å…¥ï¼Œregularizer ä¸ºæ­£åˆ™åŒ–æƒé‡ï¼Œè¿”å›å€¼ä¸ºé¢„æµ‹æˆ–åˆ†ç±»ç»“æœ yã€‚

```
def get_weight(shape, regularizer):
	w = tf.Variable( )
	tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(regularizer)(w)) 
	return w
```

ç¬¬äºŒä¸ªå‡½æ•° get_weight() å¯¹å‚æ•° w è®¾å®šã€‚è¯¥å‡½æ•°ä¸­ï¼Œå‚æ•° shape è¡¨ç¤ºå‚æ•° w çš„å½¢çŠ¶ï¼Œregularizer è¡¨ç¤ºæ­£åˆ™åŒ–æƒé‡ï¼Œè¿”å›å€¼ä¸ºå‚æ•° wã€‚å…¶ä¸­ï¼Œtf.variable()ç»™ w èµ‹åˆå€¼ï¼Œ tf.add_to_collection() è¡¨ç¤ºå°†å‚æ•° w æ­£åˆ™åŒ–æŸå¤±åŠ åˆ°æ€»æŸå¤± losses ä¸­ã€‚

```
def get_bias(shape):
	b = tf.Variable(    )
	return b
```

ç¬¬ä¸‰ä¸ªå‡½æ•° get_bias()å¯¹å‚æ•° b è¿›è¡Œè®¾å®šã€‚è¯¥å‡½æ•°ä¸­ï¼Œå‚æ•° shape è¡¨ç¤ºå‚æ•° b çš„å½¢çŠ¶,è¿”å›å€¼ä¸ºå‚æ•° bã€‚å…¶ä¸­ tf.variable()è¡¨ç¤ºç»™ w èµ‹åˆå€¼ã€‚

**åå‘ä¼ æ’­ï¼šè®­ç»ƒç½‘ç»œï¼Œä¼˜åŒ–ç½‘ç»œå‚æ•°ï¼Œæé«˜æ¨¡å‹å‡†ç¡®æ€§ã€‚**

```
def backward( ):
	x = tf.placeholder( )
	y_ = tf.placeholder( )
	y = forward.forward(x, REGULARIZER) 
	global_step = tf.Variable(0, trainable=False) 
	loss =
```

å‡½æ•° backward()ä¸­ï¼Œplaceholder()å®ç°å¯¹æ•°æ®é›† x å’Œæ ‡å‡†ç­”æ¡ˆ y_å ä½ï¼Œforward.forward()å®ç°å‰å‘ä¼ æ’­çš„ç½‘ç»œç»“æ„ï¼Œå‚æ•° global_step è¡¨ç¤ºè®­ç»ƒè½®æ•°ï¼Œè®¾ç½®ä¸ºä¸å¯è®­ç»ƒå‹å‚æ•°ã€‚

åœ¨è®­ç»ƒç½‘ç»œæ¨¡å‹æ—¶ï¼Œå¸¸å°†æ­£åˆ™åŒ–ã€æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡å’Œæ»‘åŠ¨å¹³å‡è¿™ä¸‰ä¸ªæ–¹æ³•ä½œä¸ºæ¨¡å‹ä¼˜åŒ–æ–¹æ³•ã€‚

åœ¨ Tensorflow ä¸­ï¼Œæ­£åˆ™åŒ–è¡¨ç¤ºä¸ºï¼š

é¦–å…ˆï¼Œè®¡ç®—é¢„æµ‹ç»“æœä¸æ ‡å‡†ç­”æ¡ˆçš„æŸå¤±å€¼ã€‚

1ã€MSEï¼š

```
 y ä¸ y_çš„å·®è·(loss_mse) = tf.reduce_mean(tf.square(y-y_))
```

2ã€äº¤å‰ç†µï¼š

```
ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))
```

y ä¸ y_çš„å·®è·ï¼š

```
cem = tf.reduce_mean(ce) 
```

3ã€è‡ªå®šä¹‰ï¼šy ä¸ y_çš„å·®è·

å…¶æ¬¡ï¼Œæ€»æŸå¤±å€¼ä¸ºé¢„æµ‹ç»“æœä¸æ ‡å‡†ç­”æ¡ˆçš„æŸå¤±å€¼åŠ ä¸Šæ­£åˆ™åŒ–é¡¹ã€‚

```
loss = y ä¸ y_çš„å·®è· + tf.add_n(tf.get_collection('losses'))
```

åœ¨ Tensorflow ä¸­ï¼ŒæŒ‡æ•°è¡°å‡å­¦ä¹ ç‡è¡¨ç¤ºä¸ºï¼š

```
learning_rate = tf.train.exponential_decay(
	LEARNING_RATE_BASE, 
	global_step,
	æ•°æ®é›†æ€»æ ·æœ¬æ•° / BATCH_SIZE,
	LEARNING_RATE_DECAY,
	staircase=True)
train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)
```

åœ¨ Tensorflow ä¸­ï¼Œæ»‘åŠ¨å¹³å‡è¡¨ç¤ºä¸ºï¼š

```
ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step) 
ema_op = ema.apply(tf.trainable_variables())
with tf.control_dependencies([train_step, ema_op]):
	train_op = tf.no_op(name='train')
```

å…¶ä¸­ï¼Œæ»‘åŠ¨å¹³å‡å’ŒæŒ‡æ•°è¡°å‡å­¦ä¹ ç‡ä¸­çš„ global_step ä¸ºåŒä¸€ä¸ªå‚æ•°ã€‚

ç”¨ with ç»“æ„åˆå§‹åŒ–æ‰€æœ‰å‚æ•°ï¼š

```
with tf.Session() as sess:
	init_op = tf.global_variables_initializer() 
		sess.run(init_op)
	for i in range(STEPS):
		sess.run(train_step,feed_dict={x: ,y_: })
			if i % è½®æ•° == 0:
			print
```

å…¶ä¸­ï¼Œwith ç»“æ„ç”¨äºåˆå§‹åŒ–æ‰€æœ‰å‚æ•°ä¿¡æ¯ä»¥åŠå®ç°è°ƒç”¨è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶æ‰“å°å‡º loss å€¼ã€‚

åˆ¤æ–­ python è¿è¡Œæ–‡ä»¶æ˜¯å¦ä¸ºä¸»æ–‡ä»¶ï¼š

```
if __name__=='__main__':
backward()
```

è¯¥éƒ¨åˆ†ç”¨æ¥åˆ¤æ–­ python è¿è¡Œçš„æ–‡ä»¶æ˜¯å¦ä¸ºä¸»æ–‡ä»¶ã€‚è‹¥æ˜¯ä¸»æ–‡ä»¶ï¼Œåˆ™æ‰§è¡Œbackword() å‡½æ•°ã€‚